{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f453e9e-02c2-4dc7-8ce7-eefa3c523c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully!!!\n"
     ]
    }
   ],
   "source": [
    "# Loading gc library to remove old data or cache files of the system that are relevant to the program\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# loading pandas, os, datetime, numpy for data management work of the project.\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Once succefully loaded we will see \"Loaded successfully!!!\" message after the cell.\n",
    "print(\"Loaded successfully!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdbba7e-bb22-445c-8c73-d03440112a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Input\\Line_Listing_Row.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Remember to update file path before running any section.\n",
    "\n",
    "# Please update file_path , before start your work. \n",
    "# This will help us in to get the correct sheet\n",
    "\n",
    "# Narendra Singh System's directory\n",
    "# Specify the path to your Excel file\n",
    "#base_dir  = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Raw_Data\"\n",
    "\n",
    "# Julfacar Kassar System's directory\n",
    "#Specify the path to your Excel file\n",
    "base_dir  = r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Input\"\n",
    "\n",
    "#output_base_dir = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\P23018_\\Output_data\\USAID_Staff_Daily_Dairy\\underprocessing\"\n",
    "excel_file = \"Line_Listing_Row.xlsx\"\n",
    "file_path = os.path.join(base_dir, excel_file)\n",
    "\n",
    "#file_path = r'E:\\MHIMC\\WorkingFolder\\Working_Folder\\MKN(MamtaKnowledgeNetwork)\\DataAnalysis_Using_Python\\Draft_Project1\\SurveyReport_20231123095033.xlsx'\n",
    "\n",
    "try:\n",
    "    line_list_raw_df = pd.read_excel(file_path)\n",
    "    print(\"Dataset loaded successfully from:\", file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0961ef0-db93-4667-981f-6d0c466f1069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\MHIMC-JULFAKAR\\AppData\\Local\\Temp\\ipykernel_16956\\1879271915.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  header_start_index = df.index[df.apply(lambda x: str(x[0]).startswith('SrNo'), axis=1)].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Line_List_Process.xlsx\n",
      "Column names in the DataFrame: ['SrNo', 'MISID', 'FormEvalGUID', 'ParentEvalGUID', 'FollowUpParentEvalGUID', 'ProjectYear', 'ReportingMode', 'State', 'District', 'Block', 'Village', 'UserName', 'StartTime', 'EndTime', 'Longitude', 'Latitude', 'UpdatedOn', 'MHU Location', 'Sub-Centre Pasgawa', 'Gram Panchayat (Pasgawa)', 'Asha (Pasgawa)', 'Sub Centre (Bharkhani)', 'Gram Panchayat  (Bharkhani)', 'ASHA (Bharkhani)', 'Sub Centre (Todarpur)', 'Gram Panchayat  (Todarpur)', 'ASHA (Todarpur)', 'Sub-Centre (Hariyawan)', 'Gram Panchayat  (Hariyawan)', 'ASHA (Hariyawan)', 'Sub-Centre (Ladpura)', 'Gram Panchayat (Ladpura)', 'Asha Name (Ladpura)', 'Date of identifictaion', 'Beneficiary ID', 'Name of the beneficiary', 'Husband Name', 'Age of the beneficiary', 'Address of the beneficiary', 'Contact Number', 'Type of beneficiary', 'Age at Marriage of the Beneficiary', 'Age at First Pregnancy of the beneficiary ', 'Number of previous live births', 'Do you have any disabilities?', 'If yes, type of disabilities?', 'Date of Last Menstrual Period', 'Present month of pregnancy', 'Expected date of delivery', 'Did you registered your pregnancy?', 'Does the beneficiary have ANC registration Card ?', 'MCP Card Number', 'Date of registration of current pregnancy', 'What was your initial weight during pregnancy registration?', 'By whom ANC is done', 'Where you have availed Service', 'Date of delivery', 'Have you availed of JSY benefit?', 'Total Cost incurred during delivery']\n"
     ]
    }
   ],
   "source": [
    "# loading pandas, os, datetime, numpy for data management work of the project.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to get the output directory\n",
    "def get_output_directory():\n",
    "    return r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\"\n",
    "    #return r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Output\"\n",
    "\n",
    "# Additional code for processing a DataFrame\n",
    "def process_dataframe(df):\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d%m%y%H%M')\n",
    "    \n",
    "    # Create a folder with the current date as its name\n",
    "    today_date = now.strftime(\"%Y-%m-%d\")\n",
    "    today_output_folder = os.path.join(get_output_directory(), today_date)\n",
    "    \n",
    "    if not os.path.exists(today_output_folder):\n",
    "        os.makedirs(today_output_folder)\n",
    "    \n",
    "    # Define the output file path inside the folder\n",
    "    output_file_path = os.path.join(today_output_folder, \"Line_List_Process.xlsx\")\n",
    "    \n",
    "    # Find the index where headers start (assumed to start with 'SrNo')\n",
    "    header_start_index = df.index[df.apply(lambda x: str(x[0]).startswith('SrNo'), axis=1)].tolist()\n",
    "    \n",
    "    if header_start_index:\n",
    "        header_index = header_start_index[0] - 1\n",
    "        header_row_1 = df.iloc[header_index]\n",
    "        header_row_2 = df.iloc[header_index + 1]\n",
    "        \n",
    "        # Merge header rows if necessary\n",
    "        df.iloc[header_index + 1] = np.where(header_row_2.apply(lambda x: isinstance(x, (int, float))), np.nan, header_row_2)\n",
    "        df.iloc[header_index] = np.where(header_row_1.isnull(), df.iloc[header_index + 1], header_row_1)\n",
    "        \n",
    "        # Set the merged header as dataframe header\n",
    "        df.columns = df.iloc[header_index]\n",
    "        # Drop the rows used as headers and any rows before them\n",
    "        df = df.drop(np.arange(header_index + 1))\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # Drop any rows that are entirely NaN\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    # This ensures the first row with data is not dropped\n",
    "    df = df.drop(0) if df.index[0] == 0 else df\n",
    "    # Add a dummy count column\n",
    "    df['dummy_count'] = 1\n",
    "\n",
    "    # Add a new variable named \"today\" with today's date\n",
    "    today = datetime.today()\n",
    "    df['today'] = today\n",
    "\n",
    "    # Trim leading and trailing spaces from column names  **(New code added here)**\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    \n",
    "    # Save the processed DataFrame\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "    print(f'DataFrame saved to: {output_file_path}')\n",
    "\n",
    "def main():\n",
    "    # Read Line_Listing data\n",
    "    #base_dir  = r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Input\"\n",
    "    #base_dir  = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Raw_Data\"\n",
    "    excel_file = \"Line_Listing_Row.xlsx\"\n",
    "    file_path = os.path.join(base_dir, excel_file)\n",
    "    line_list_raw_df = pd.read_excel(file_path)\n",
    "\n",
    "    # Process and save Line_Listing data frame using additional code\n",
    "    process_dataframe(line_list_raw_df)\n",
    "    # Print the column names to identify the correct ones\n",
    "    print(\"Column names in the DataFrame:\", line_list_raw_df.columns.tolist())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b5e0d4-1412-43a0-aa45-44e860dfe05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame with age groups saved successfully as 'D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Line_List_Processed.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Update\n",
    "# 1. Identification month has been added.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "def get_output_directory():\n",
    "    today_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    # NSS file system\n",
    "    #return os.path.join(\"D:\\\\Current_User-Narendra\\\\Working_Folder\\\\Projects\\\\Ongoing\\\\DCM\\\\Output\", today_date)\n",
    "\n",
    "    # JK file system\n",
    "    return os.path.join(\"D:\\\\Current_User -Julfakar\\\\New Session 2023-24\\\\Python Working\\\\MHU\\\\Output\", today_date)\n",
    "\n",
    "\n",
    "def map_age_to_group(age):\n",
    "    if age <= 19:\n",
    "        return \"LessThan19\"\n",
    "    elif 20 <= age <= 24:\n",
    "        return \"20-24\"\n",
    "    elif 25 <= age <= 29:\n",
    "        return \"25-29\"\n",
    "    elif 30 <= age <= 34:\n",
    "        return \"30-34\"\n",
    "    elif age >= 35:\n",
    "        return \"MoreThan35\"\n",
    "    else:\n",
    "        return \"Unknown\"  # For handling any missing or invalid data\n",
    "\n",
    "\n",
    "def map_days_to_trimester(days):\n",
    "    if pd.isnull(days):\n",
    "        return \"Flag\"\n",
    "    elif 0 < days <= 84:\n",
    "        return \"First Trimester\"\n",
    "    elif 85 <= days <= 168:\n",
    "        return \"Second Trimester\"\n",
    "    elif 169 <= days <= 280:\n",
    "        return \"Third Trimester\"\n",
    "    elif 281 <= days <= 320:\n",
    "        return \"Flag\"\n",
    "    else:\n",
    "        return \"Flag\"\n",
    "\n",
    "\n",
    "def extract_month_name_from_date(date_column):\n",
    "    # Parsing the datetime with the correct format\n",
    "    date_parsed = pd.to_datetime(date_column, format='%d-%m-%Y %H:%M:%S')\n",
    "    # Formatting to get the abbreviated month name\n",
    "    month_name = date_parsed.dt.strftime('%b')  # %b gives the abbreviated month name like 'Jan', 'Feb', 'Mar', ...\n",
    "    return month_name\n",
    "\n",
    "\n",
    "# Assuming the filename is consistent and known\n",
    "filename = \"Line_List_Process.xlsx\"\n",
    "\n",
    "# Use the get_output_directory function to dynamically set the data_file path\n",
    "data_file = os.path.join(get_output_directory(), filename)\n",
    "\n",
    "desired_variables = [\n",
    "    \"State\",\n",
    "    \"District\",\n",
    "    \"Block\",\n",
    "    \"Village\",\n",
    "    \"UserName\",\n",
    "    \"Date of identifictaion\",  # typo correction\n",
    "    \"Beneficiary ID\",\n",
    "    \"Name of the beneficiary\",\n",
    "    \"Age of the beneficiary\",\n",
    "    \"Contact Number\",\n",
    "    \"Type of beneficiary\",\n",
    "    \"Age at Marriage of the Beneficiary\",\n",
    "    \"Age at First Pregnancy of the beneficiary\",\n",
    "    \"Number of previous live births\",\n",
    "    \"Do you have any disabilities?\",\n",
    "    \"Date of Last Menstrual Period\",\n",
    "    \"Expected date of delivery\",\n",
    "    \"Did you registered your pregnancy?\",\n",
    "    \"Does the beneficiary have ANC registration Card ?\",\n",
    "    \"Date of registration of current pregnancy\",\n",
    "    \"What was your initial weight during pregnancy registration?\",\n",
    "    \"By whom ANC is done\",\n",
    "    \"Where you have availed Service\",\n",
    "    \"Date of delivery\",\n",
    "    \"Have you availed of JSY benefit?\",\n",
    "    \"MCP Card Number\",\n",
    "    \"dummy_count\",\n",
    "    \"today\",\n",
    "     \"Identification_Month\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Read the data file\n",
    "    df = pd.read_excel(data_file)\n",
    "\n",
    "    # Map the age variables to age groups\n",
    "    df['Age_Group_Beneficiary'] = df['Age of the beneficiary'].apply(map_age_to_group)\n",
    "    df['Age_Group at Marriage of the Beneficiary'] = df['Age at Marriage of the Beneficiary'].apply(map_age_to_group)\n",
    "    df['Age_Group at First Pregnancy of the beneficiary'] = df['Age at First Pregnancy of the beneficiary'].apply(map_age_to_group)\n",
    "    \n",
    "    # Calculate days between 'Date of Last Menstrual Period' and 'Date of registration of current pregnancy'\n",
    "    df['DateCalc'] = (df['Date of registration of current pregnancy'] - df['Date of Last Menstrual Period']).dt.days\n",
    "\n",
    "    # Ensure \"Expected date of delivery\" is in datetime format\n",
    "    # Create the \"EDD Pass\" column based on the condition, mapping True to \"Yes\" and False to \"No\"\n",
    "    df['Expected date of delivery'] = pd.to_datetime(df['Expected date of delivery'])\n",
    "    df['EDD Pass'] = df['Expected date of delivery'] <= df['today']\n",
    "    df['EDD Pass'] = df['EDD Pass'].map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    # New section: Calculate the month from \"Date of identification\"\n",
    "    df['Identification_Month'] = extract_month_name_from_date(df['Date of identifictaion'])\n",
    "\n",
    "    # Map the calculated days to trimester categories\n",
    "    df['Trimester'] = df['DateCalc'].apply(map_days_to_trimester)\n",
    "\n",
    "    # Ensure all desired variables are present in the data\n",
    "    missing_vars = set(desired_variables) - set(df.columns)\n",
    "    if missing_vars:\n",
    "        print(f\"Warning: Variables {missing_vars} not found in the data file.\")\n",
    "\n",
    "    # Add the new age group variables to the list of desired variables\n",
    "    desired_variables.extend(['Identification_Month','Age_Group_Beneficiary', 'Age_Group at Marriage of the Beneficiary', 'Age_Group at First Pregnancy of the beneficiary','DateCalc', 'Trimester','EDD Pass'])\n",
    "    \n",
    "    # Select only the desired variables\n",
    "    filtered_df = df[desired_variables]\n",
    "\n",
    "    # Prepare the output directory (for saving the filtered file)\n",
    "    output_directory = get_output_directory()\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Define the output file path for the filtered DataFrame\n",
    "    output_file_path = os.path.join(output_directory, \"Line_List_Processed.xlsx\")\n",
    "    \n",
    "    # Save the filtered DataFrame\n",
    "    filtered_df.to_excel(output_file_path, index=False)\n",
    "    print(f\"Filtered DataFrame with age groups saved successfully as '{output_file_path}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {data_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb99306-6269-450c-b0c0-3a13387e0939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Line_List_Processed_FY23-24.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_output_directory():\n",
    "    \"\"\"Function to get the output directory.\"\"\"\n",
    "    #NSS System\n",
    "    #return r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Output\"\n",
    "    #JK System\n",
    "    return r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\"\n",
    "\n",
    "def process_dataframe(df):\n",
    "    \"\"\"Function to process the DataFrame and save results based on conditions.\"\"\"\n",
    "    # Trim leading and trailing spaces from column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Convert 'StartTime' to datetime\n",
    "    df['Date of identifictaion'] = pd.to_datetime(df['Date of identifictaion'], format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "    # Define the date range for filtering\n",
    "    start_date = pd.Timestamp('2023-04-01')\n",
    "    end_date = pd.Timestamp('2025-03-31')\n",
    "\n",
    "    # Filter the DataFrame based on the 'StartTime' within the specified date range\n",
    "    filtered_df = df[(df['Date of identifictaion'] >= start_date) & (df['Date of identifictaion'] <= end_date)]\n",
    "    # Sort the DataFrame by 'Date of identification' in ascending order\n",
    "    filtered_df = filtered_df.sort_values(by='Date of identifictaion', ascending=True)\n",
    "\n",
    "    # Define the path for the output Excel file\n",
    "    today_output_folder = datetime.now().strftime(\"%Y-%m-%d\")  # Use today's date for folder name\n",
    "    output_dir = os.path.join(get_output_directory(), today_output_folder)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save the filtered DataFrame for the specific date range\n",
    "    filtered_output_file_path = os.path.join(output_dir, \"Line_List_Processed_FY23-24.xlsx\")\n",
    "    filtered_df.to_excel(filtered_output_file_path, index=False)\n",
    "    print(f\"Filtered DataFrame saved to: {filtered_output_file_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load and process the DataFrame.\"\"\"\n",
    "    today_output_folder = datetime.now().strftime(\"%Y-%m-%d\")  # Dynamic date part\n",
    "    input_dir = os.path.join(get_output_directory(), today_output_folder)  # Updated to use dynamic date\n",
    "    input_file_path = os.path.join(input_dir, \"Line_List_Processed.xlsx\")\n",
    "\n",
    "    # Check if the file exists before attempting to load\n",
    "    if os.path.exists(input_file_path):\n",
    "        # Load the DataFrame\n",
    "        line_list_raw_df = pd.read_excel(input_file_path)\n",
    "        # Process the DataFrame\n",
    "        process_dataframe(line_list_raw_df)\n",
    "    else:\n",
    "        print(f\"No file found at {input_file_path}. Please check the path and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c481dcde-b1a4-41cd-bd9c-4b1b0150a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to 'D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Line_List_QAQC.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Update\n",
    "# NS\n",
    "#  1. added new condition of  pregnant_condition into Reg_weight\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_output_directory():\n",
    "    \"\"\"Function to get the output directory.\"\"\"\n",
    "    #NSS System\n",
    "    #return r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Output\"\n",
    "    #JK System\n",
    "    return r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\"\n",
    "    \n",
    "def further_process_dataframe(filtered_df):\n",
    "    \"\"\"Function to further process the filtered DataFrame and save to Excel.\"\"\"\n",
    "    # Trim leading and trailing spaces from column names\n",
    "    filtered_df.columns = filtered_df.columns.str.strip()\n",
    "    \n",
    "    # Define the columns to keep\n",
    "    Line_list_keep_var = [\n",
    "        'State', 'District', 'Block', 'Village', 'UserName', 'Beneficiary ID', 'Name of the beneficiary',\n",
    "        'What was your initial weight during pregnancy registration?', \n",
    "        'Age of the beneficiary', 'Contact Number', 'Type of beneficiary', \n",
    "        'Age at Marriage of the Beneficiary', \n",
    "        'Age at First Pregnancy of the beneficiary', 'Number of previous live births', 'MCP Card Number' , 'dummy_count', 'EDD Pass'\n",
    "    ]\n",
    "\n",
    "    # Filter the DataFrame to keep only the specified columns\n",
    "    filtered_df = filtered_df[Line_list_keep_var]\n",
    "\n",
    "    # Define the path for the output Excel file\n",
    "    today_output_folder = datetime.now().strftime(\"%Y-%m-%d\")  # Use today's date for folder name\n",
    "    output_dir = os.path.join(get_output_directory(), today_output_folder)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file_path = os.path.join(output_dir, \"Line_List_QAQC.xlsx\")\n",
    "\n",
    "    # Use a writer object to write multiple DataFrames to the same Excel file\n",
    "    with pd.ExcelWriter(output_file_path) as writer:\n",
    "        # Initial filter for \"Pregnant\" women\n",
    "        pregnant_condition = filtered_df[\"Type of beneficiary\"] == \"Pregnant\"\n",
    "\n",
    "        # Weight check condition, adjusted to include only \"Pregnant\" women\n",
    "        weight_condition = (filtered_df[\"What was your initial weight during pregnancy registration?\"].isna() | (filtered_df[\"What was your initial weight during pregnancy registration?\"] < 35)) & pregnant_condition\n",
    "\n",
    "        # Apply combined conditions to filter the DataFrame and write to Excel\n",
    "        filtered_df[weight_condition].to_excel(writer, sheet_name='Reg_Weight', index=False)\n",
    "        \n",
    "        # Age Check\n",
    "        age_condition = filtered_df[\"Age of the beneficiary\"] < 18\n",
    "        filtered_df[age_condition].to_excel(writer, sheet_name='Current_AgeCheck', index=False)\n",
    "        \n",
    "        # Marriage Age Check\n",
    "        marriage_age_condition = filtered_df[\"Age at Marriage of the Beneficiary\"] <= 15\n",
    "        filtered_df[marriage_age_condition].to_excel(writer, sheet_name='Marriage_Age_15', index=False)\n",
    "        \n",
    "        # First Pregnancy Age Check\n",
    "        first_pregnancy_condition = filtered_df[\"Age at First Pregnancy of the beneficiary\"] < 18\n",
    "        filtered_df[first_pregnancy_condition].to_excel(writer, sheet_name='1_Preg_Age', index=False)\n",
    "\n",
    "        # Pgt Before Marriage Check\n",
    "        pgt_before_marriage_condition = filtered_df[\"Age at First Pregnancy of the beneficiary\"] < filtered_df[\"Age at Marriage of the Beneficiary\"]\n",
    "        filtered_df[pgt_before_marriage_condition].to_excel(writer, sheet_name='PgtBeforeMarriage', index=False)\n",
    "\n",
    "    print(f\"Data processed and saved to '{output_file_path}'\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load, process, and further process the DataFrame.\"\"\"\n",
    "    today_output_folder = datetime.now().strftime(\"%Y-%m-%d\")  # Dynamic date part\n",
    "    input_dir = os.path.join(get_output_directory(), today_output_folder)  # Updated to use dynamic date\n",
    "    input_file_path = os.path.join(input_dir, \"Line_List_Processed_FY23-24.xlsx\")\n",
    "\n",
    "    # Check if the file exists before attempting to load\n",
    "    if os.path.exists(input_file_path):\n",
    "        # Load the DataFrame\n",
    "        line_list_raw_df = pd.read_excel(input_file_path)\n",
    "        # Further process the filtered DataFrame and save to Excel\n",
    "        further_process_dataframe(line_list_raw_df)\n",
    "    else:\n",
    "        print(f\"No file found at {input_file_path}. Please check the path and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "135bd222-298a-4005-8016-9089b731cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MHIMC-JULFAKAR\\AppData\\Local\\Temp\\ipykernel_16956\\3741460913.py:63: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  age_df[age_condition].to_excel(writer, sheet_name='Current_AgeCheck', index=False)\n",
      "C:\\Users\\MHIMC-JULFAKAR\\AppData\\Local\\Temp\\ipykernel_16956\\3741460913.py:72: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  marriage_age_df[marriage_age_condition].to_excel(writer, sheet_name='Marriage_Age_15', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to 'D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Line_List_QAQC.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Update\n",
    "# NS\n",
    "#  1. added new condition of  pregnant_condition into Reg_weight\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_output_directory():\n",
    "    \"\"\"Function to get the output directory.\"\"\"\n",
    "    #NSS System\n",
    "    #return r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Output\"\n",
    "    #JK System\n",
    "    return r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\"\n",
    "\n",
    "def further_process_dataframe(filtered_df):\n",
    "    \"\"\"Function to further process the filtered DataFrame and save to Excel.\"\"\"\n",
    "    # Trim leading and trailing spaces from column names\n",
    "    filtered_df.columns = filtered_df.columns.str.strip()\n",
    "    \n",
    "    # Define the columns to keep\n",
    "    Line_list_keep_var = [\n",
    "        'State', 'District', 'Block', 'Village', 'UserName', 'Beneficiary ID', 'Name of the beneficiary',\n",
    "        'What was your initial weight during pregnancy registration?', \n",
    "        'Age of the beneficiary', 'Contact Number', 'Type of beneficiary', \n",
    "        'Age at Marriage of the Beneficiary', \n",
    "        'Age at First Pregnancy of the beneficiary', 'Number of previous live births', 'MCP Card Number' , 'dummy_count', \n",
    "        'Identification_Month','Age_Group_Beneficiary', 'Age_Group at Marriage of the Beneficiary', \n",
    "        'Age_Group at First Pregnancy of the beneficiary','DateCalc', 'Trimester'\n",
    "    ]\n",
    "\n",
    "    # Filter the DataFrame to keep only the specified columns\n",
    "    filtered_df = filtered_df[Line_list_keep_var]\n",
    "\n",
    "    # Group by 'District', 'Block', 'Village', 'UserName' and calculate totals\n",
    "    grouped_df = filtered_df.groupby(['District', 'Block', 'Village', 'UserName']).size().reset_index(name='Total Count')\n",
    "\n",
    "    # Define the path for the output Excel file\n",
    "    today_output_folder = datetime.now().strftime(\"%Y-%m-%d\")  # Use today's date for folder name\n",
    "    output_dir = os.path.join(get_output_directory(), today_output_folder)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file_path = os.path.join(output_dir, \"Line_List_QAQC.xlsx\")\n",
    "\n",
    "        # Use a writer object to write multiple DataFrames to the same Excel file\n",
    "    with pd.ExcelWriter(output_file_path) as writer:\n",
    "        # Initial filter for \"Pregnant\" women\n",
    "        pregnant_condition = filtered_df[\"Type of beneficiary\"] == \"Pregnant\"\n",
    "        # Weight check condition, adjusted to include only \"Pregnant\" women\n",
    "        weight_condition = (filtered_df[\"What was your initial weight during pregnancy registration?\"].isna() | (filtered_df[\"What was your initial weight during pregnancy registration?\"] < 35)) & pregnant_condition\n",
    "        weight_df = filtered_df[weight_condition]\n",
    "        weight_df.to_excel(writer, sheet_name='Reg_Weight', index=False)\n",
    "        \n",
    "        # Group by 'District', 'Block',  'UserName' and sum 'dummy_count' for 'Reg_Weight_Summary'\n",
    "        reg_weight_summary = weight_df.groupby(['District', 'Block', 'UserName'])['dummy_count'].sum().reset_index(name='Total_Dummy_Count')\n",
    "        reg_weight_summary.to_excel(writer, sheet_name='Reg_Weight_Summary', index=False)\n",
    "        \n",
    "        # Other checks as before\n",
    "        # Age Check\n",
    "        age_condition = filtered_df[\"Age of the beneficiary\"] < 18\n",
    "        age_df = filtered_df[age_condition]\n",
    "        age_df[age_condition].to_excel(writer, sheet_name='Current_AgeCheck', index=False)\n",
    "\n",
    "        # Group by 'District', 'Block',  'UserName' and sum 'dummy_count' for 'Current_AgeCheck_Summary'\n",
    "        age_df_summary = age_df.groupby(['District', 'Block', 'UserName'])['dummy_count'].sum().reset_index(name='Total_Dummy_Count')\n",
    "        age_df_summary.to_excel(writer, sheet_name='Current_AgeCheck_Summary', index=False)\n",
    "\n",
    "        # Marriage Age Check\n",
    "        marriage_age_condition = filtered_df[\"Age at Marriage of the Beneficiary\"] <= 15\n",
    "        marriage_age_df = filtered_df[marriage_age_condition]\n",
    "        marriage_age_df[marriage_age_condition].to_excel(writer, sheet_name='Marriage_Age_15', index=False)\n",
    "\n",
    "        # Group by 'District', 'Block',  'UserName' and sum 'dummy_count' for 'marriage_age_Summary'\n",
    "        marriage_age_df_summary = marriage_age_df.groupby(['District', 'Block', 'UserName'])['dummy_count'].sum().reset_index(name='Total_Dummy_Count')\n",
    "        marriage_age_df_summary.to_excel(writer, sheet_name='Marriage_Age_Summary', index=False)\n",
    "\n",
    "        ############################\n",
    "        # First Pregnancy Age Check\n",
    "        first_pregnancy_condition = filtered_df[\"Age at First Pregnancy of the beneficiary\"] < 18\n",
    "        filtered_df[first_pregnancy_condition].to_excel(writer, sheet_name='1_Preg_Age', index=False)\n",
    "\n",
    "        # Pgt Before Marriage Check\n",
    "        pgt_before_marriage_condition = filtered_df[\"Age at First Pregnancy of the beneficiary\"] < filtered_df[\"Age at Marriage of the Beneficiary\"]\n",
    "        filtered_df[pgt_before_marriage_condition].to_excel(writer, sheet_name='PgtBeforeMarriage', index=False)\n",
    "        \n",
    "        # Write the grouped and aggregated DataFrame to a new sheet for 'Summary_Totals'\n",
    "        grouped_df = filtered_df.groupby(['District', 'Block', 'Village', 'UserName']).size().reset_index(name='Total Count')\n",
    "        grouped_df.to_excel(writer, sheet_name='Summary_Totals', index=False)\n",
    "\n",
    "    print(f\"Data processed and saved to '{output_file_path}'\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load, process, and further process the DataFrame.\"\"\"\n",
    "    today_output_folder = datetime.now().strftime(\"%Y-%m-%d\")  # Dynamic date part\n",
    "    input_dir = os.path.join(get_output_directory(), today_output_folder)  # Updated to use dynamic date\n",
    "    input_file_path = os.path.join(input_dir, \"Line_List_Processed_FY23-24.xlsx\")\n",
    "\n",
    "    # Check if the file exists before attempting to load\n",
    "    if os.path.exists(input_file_path):\n",
    "        # Load the DataFrame\n",
    "        line_list_raw_df = pd.read_excel(input_file_path)\n",
    "        # Further process the filtered DataFrame and save to Excel\n",
    "        further_process_dataframe(line_list_raw_df)\n",
    "    else:\n",
    "        print(f\"No file found at {input_file_path}. Please check the path and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb9e6cd-1a80-4473-8a39-c28a15fe7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codefor Followup -dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aff01ce-15eb-4281-9803-3f3ba65b2527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully!!!\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "# importing library \n",
    "\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print(\"Loaded successfully!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7559bb17-08ee-43c5-b514-5860fe6079a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Input\\Follow-UP_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Please update file_path , before start your work. \n",
    "# This will help us in to get the correct sheet\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "#base_dir  = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Raw_Data\"\n",
    "#JK Specify File\n",
    "base_dir  = r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Input\"\n",
    "#output_base_dir = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\P23018_\\Output_data\\USAID_Staff_Daily_Dairy\\underprocessing\"\n",
    "excel_file = \"Follow-UP_data.xlsx\"\n",
    "file_path = os.path.join(base_dir, excel_file)\n",
    "\n",
    "#file_path = r'E:\\MHIMC\\WorkingFolder\\Working_Folder\\MKN(MamtaKnowledgeNetwork)\\DataAnalysis_Using_Python\\Draft_Project1\\SurveyReport_20231123095033.xlsx'\n",
    "\n",
    "try:\n",
    "    flw_raw_df = pd.read_excel(file_path)\n",
    "    print(\"Dataset loaded successfully from:\", file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e83874-9f27-40b9-aac2-9376fb559900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\MHIMC-JULFAKAR\\AppData\\Local\\Temp\\ipykernel_16956\\3350518891.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  header_start_index = df.index[df.apply(lambda x: str(x[0]).startswith('SrNo'), axis=1)].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Follow_up_Process.xlsx\n",
      "Column names in the DataFrame: ['SrNo', 'MISID', 'FormEvalGUID', 'ParentEvalGUID', 'FollowUpParentEvalGUID', 'ProjectYear', 'ReportingMode', 'State', 'District', 'Block', 'Village', 'UserName', 'StartTime', 'EndTime', 'Longitude', 'Latitude', 'UpdatedOn', 'ID', 'Is ASHA present during this visit?', 'Date of follow up\\n', 'Current Status', 'LMP Date', 'No of days  between LMP and ANC check up', 'Number of Follow up\\n', 'TD-1', 'TD-2 Due date\\n', 'TD-2\\n', 'TT Booster', 'Date of first ANC check up', 'Delay in Registration ', 'Reasons for delay in registration', 'Height (In Cm)', 'Weight (In Kg)', 'BMI Calculate', 'Blood Pressure (systolic)', 'Blood Pressure (Dystolic)', 'Pulse Rate', 'Random Blood Sugar', 'Glucose Test', 'Fetal Heart Rate', 'Haemoglobin checked* \\n\\n', 'HB level ', 'Did you receive IFA', 'Did you receive calcium tablets', 'Urine Test for Albumin', 'If Conducted than result of Urine Albumin test', 'If Found, state the grading', 'Per Abdomen Examination done?', 'If yes, what is the findings of Abdomen Examination', 'Did you Identified with any danger sign*\\n\\n', 'If yes, what?- Identified with_(History of Diabetes Mellitus ()', 'If yes, what?- Identified with_(Pre-Eclampsia & Eclampsia)', 'If yes, what?- Identified with_(Previous history of Abortion)', 'If yes, what?- Identified with_(Polyhydramnios (based on sonog)', 'If yes, what?- Identified with_(Twins or multiple pregnancy)', 'If yes, what?- Identified with_(Malpresentation (breech or oth)', 'If yes, what?- Identified with_(Previous Ceaser)', 'If yes, what?- Identified with_(Thyroid disease)', 'If yes, what?- Identified with_(Tuberculosis)', 'If yes, what?- Identified with_(Pregnancy with medical Disease)', 'If yes, what?- Identified with_(Previous Neonatal Death)', 'If yes, what?- Identified with_(Previous Still birth)', 'If yes, what?- Identified with_(Short Inter Pregnancy Interval)', 'If yes, what?- Identified with_(Less than 19 yrs)', 'If yes, what?- Identified with_(More than 4 children)', 'If yes, what?- Identified with_(History of PPH)', 'If yes, what?- Identified with_(History of Antepartum Hemorrha)', 'If yes, what?- Identified with_(History of Congenital Anomaly)', 'If yes, what?- Identified with_(History of Obstructed Labour)', 'If yes, what?- Identified with_(Other Specify)', 'If yes, what? Identified with any danger sign*-Other Specify', 'Total Risk factors of High Risk Pregnancy', 'Is this patient referred to government facility by MHU?', 'Referred to Government Facility', 'If Referred, specify the reason for referral. ', 'Do you consume Alcohol/ Tobacco/ Any other substance\\n\\n', ' Do you take adequate nutrition diet* (fill after probing the beneficiary)', 'Have you counselled beneficiary on maternal & child health through IEC, BCC at MHU (click the most relevant topic)', 'If Yes than what topics covere_(ANC)', 'If Yes than what topics covere_(PNC)', 'If Yes than what topics covere_(Anaemia)', 'If Yes than what topics covere_(MHM)', 'If Yes than what topics covere_(Birth Preparedness)', 'If Yes than what topics covere_(Complementary Feeding)', 'If Yes than what topics covere_(High Risk Pregnancy)', 'Is tele counseling done?', 'If Yes, tele counseling done date.', 'If Yes, were you advised for iron sucrose treatment? ', 'If Yes, how many iron sucrose injections were taken?', 'Mention the haemoglobin status before iron sucrose treatment. (Verify from report). ', 'After an iron-sucrose injection, what is the level of hemoglobin? (verify the record/do HB Test) ', 'Outcome of pregnancy ', 'If Live Birth', 'Date of Delivery/ Abortion', 'Where delivery happened ?', 'Nature of delivery', 'No of Post Natal Care services_(PNC-1 (within 2 days of Delive)', 'No of Post Natal Care services_(PNC-2 (After 3 days of Deliver)', 'No of Post Natal Care services_(PNC-3 (After 7 days of Deliver)', 'No of Post Natal Care services_(PNC-4 (After 14 day of Deliver)', 'Weight of child at time of birth (in KG)', 'Gender New Born', 'Weight of Child on MMU Visit (in KG)', 'Height of Child on MMU Visit (in CM)', 'Breastfeed within one  hour of birth', 'Child 0-6 month . Exclusive breastfed', 'At Birth BCG, Hepatitis, B-Birth dose, OPV-0', 'Currently Using Any Family Pla_(Female Sterilization)', 'Currently Using Any Family Pla_(Male Sterilization)', 'Currently Using Any Family Pla_(IUD/PPIUD)', 'Currently Using Any Family Pla_(Pills)', 'Currently Using Any Family Pla_(Condom)', 'Currently Using Any Family Pla_(None)', 'Currently Using Any Family Pla_(Other Specify)', 'Other Currently Using Any Family Planning Methods', 'Have you attended awarness meeting on PNC', 'Date of Maternal Death', 'Place of Death', 'Timing of Death', 'If Postpartum then the duration in days between delivery and death. ', 'If Intrapartum or Postpartum / Death what is a birth mode of delivery? ', 'Reasons for Deaths _(Postpartum Haemorrhage )', 'Reasons for Deaths _(Pregnancy Related Infections )', 'Reasons for Deaths _(Hypertensive Disorders )', 'Reasons for Deaths _(Abortion)', 'Reasons for Deaths _(Severe Anaemia )', 'Reasons for Deaths _(Other Specify)', 'Other specify ', 'What is the reason, according to the death certificate?', 'If Intrapartum or Postpartum death what is the status of new-born? ', 'If Abortion, Mention the type. ']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to get the output directory\n",
    "#NSS file system\n",
    "#def get_output_directory():\n",
    "    #return r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Output\"\n",
    "# JK file system\n",
    "def get_output_directory():\n",
    "    return r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\"\n",
    "    \n",
    "\n",
    "# Additional code for processing a DataFrame\n",
    "def process_dataframe(df):\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d%m%y%H%M')\n",
    "    \n",
    "    # Create a folder with the current date as its name\n",
    "    today_date = now.strftime(\"%Y-%m-%d\")\n",
    "    today_output_folder = os.path.join(get_output_directory(), today_date)\n",
    "    \n",
    "    if not os.path.exists(today_output_folder):\n",
    "        os.makedirs(today_output_folder)\n",
    "    \n",
    "    # Define the output file path inside the folder\n",
    "    output_file_path = os.path.join(today_output_folder, \"Follow_up_Process.xlsx\")\n",
    "    \n",
    "    # Find the index where headers start (assumed to start with 'SrNo')\n",
    "    header_start_index = df.index[df.apply(lambda x: str(x[0]).startswith('SrNo'), axis=1)].tolist()\n",
    "    \n",
    "    if header_start_index:\n",
    "        header_index = header_start_index[0] - 1\n",
    "        header_row_1 = df.iloc[header_index]\n",
    "        header_row_2 = df.iloc[header_index + 1]\n",
    "        \n",
    "        # Merge header rows if necessary\n",
    "        df.iloc[header_index + 1] = np.where(header_row_2.apply(lambda x: isinstance(x, (int, float))), np.nan, header_row_2)\n",
    "        df.iloc[header_index] = np.where(header_row_1.isnull(), df.iloc[header_index + 1], header_row_1)\n",
    "        \n",
    "        # Set the merged header as dataframe header\n",
    "        df.columns = df.iloc[header_index]\n",
    "        # Drop the rows used as headers and any rows before them\n",
    "        df = df.drop(np.arange(header_index + 1))\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # Drop any rows that are entirely NaN\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    # This ensures the first row with data is not dropped\n",
    "    df = df.drop(0) if df.index[0] == 0 else df\n",
    "    # Add a dummy count column\n",
    "    df['dummy_count'] = 1\n",
    "    \n",
    "    # Save the processed DataFrame\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "    print(f'DataFrame saved to: {output_file_path}')\n",
    "\n",
    "def main():\n",
    "    # Read Follow up data\n",
    "    #NSS file System\n",
    "    #base_dir  = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Raw_Data\"\n",
    "    #JK file System\n",
    "    base_dir  = r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Input\"\n",
    "    excel_file = \"Follow-UP_data.xlsx\"\n",
    "    file_path = os.path.join(base_dir, excel_file)\n",
    "    flw_raw_df = pd.read_excel(file_path)\n",
    "\n",
    "    # Process and save Line_Listing data frame using additional code\n",
    "    process_dataframe(flw_raw_df)\n",
    "    # Print the column names to identify the correct ones\n",
    "    print(\"Column names in the DataFrame:\", flw_raw_df.columns.tolist())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62c8f2cd-83f2-4ae0-9e57-761cc4057053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Follow_up_Processed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to trim spaces from all string values in the DataFrame\n",
    "def trim_spaces(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":  # Only apply to columns with data type 'object' (string)\n",
    "            df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Define the base directory and file names\n",
    "#NSS file system\n",
    "#base_dir = \"D:\\\\Current_User-Narendra\\\\Working_Folder\\\\Projects\\\\Ongoing\\\\DCM\\\\Output\"\n",
    "\n",
    "#JK File System\n",
    "base_dir = \"D:\\\\Current_User -Julfakar\\\\New Session 2023-24\\\\Python Working\\\\MHU\\\\Output\"\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "input_file_dir = os.path.join(base_dir, today_date)  # Assuming this is the original file path\n",
    "\n",
    "input_file_path = os.path.join(input_file_dir, \"Follow_up_Process.xlsx\")  # Assuming this is the original file path\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(input_file_path)\n",
    "\n",
    "# Trim leading and trailing spaces\n",
    "df_cleaned = trim_spaces(df)\n",
    "\n",
    "# Define the output directory and create it if it doesn't exist\n",
    "output_directory = os.path.join(base_dir, today_date)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(output_directory, \"Follow_up_Processed.xlsx\")\n",
    "\n",
    "# Save the cleaned DataFrame to a new Excel file\n",
    "df_cleaned.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned DataFrame saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfae1760-357d-4363-80e0-821c47875492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\PBI_Follow_up_Processed.xlsx\n",
      "Unique ID dataset saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Unique_FLW_Case.xlsx\n",
      "Multiple ID dataset saved to: D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\\2024-04-25\\Multiple_IDs_FLW_Case.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# List of variables to remove\n",
    "variables_to_remove = [\n",
    "    \"Currently Using Any Family Pla_(Female Sterilization)\",\n",
    "    \"Currently Using Any Family Pla_(Male Sterilization)\",\n",
    "    \"Currently Using Any Family Pla_(IUD/PPIUD)\",\n",
    "    \"Currently Using Any Family Pla_(Pills)\",\n",
    "    \"Currently Using Any Family Pla_(Condom)\",\n",
    "    \"Currently Using Any Family Pla_(None)\",\n",
    "    \"Currently Using Any Family Pla_(Other Specify)\",\n",
    "    \"Other Currently Using Any Family Planning Methods\",\n",
    "    \"Have you attended awarness meeting on PNC\",\n",
    "    \"Date of Maternal Death\",\n",
    "    \"Place of Death\",\n",
    "    \"Timing of Death\",\n",
    "    \"If Postpartum then the duration in days between delivery and death. \",\n",
    "    \"If Intrapartum or Postpartum / Death what is a birth mode of delivery?\",\n",
    "    \"Reasons for Deaths _(Postpartum Haemorrhage )\",\n",
    "    \"Reasons for Deaths _(Pregnancy Related Infections )\",\n",
    "    \"Reasons for Deaths _(Hypertensive Disorders )\",\n",
    "    \"Reasons for Deaths _(Abortion)\",\n",
    "    \"Reasons for Deaths _(Severe Anaemia )\",\n",
    "    \"Reasons for Deaths _(Other Specify)\",\n",
    "    \"Other specify \",\n",
    "    \"What is the reason, according to the death certificate?\",\n",
    "    \"If Intrapartum or Postpartum death what is the status of new-born? \",\n",
    "    \"If Abortion, Mention the type. \"\n",
    "]\n",
    "\n",
    "# Removing the specified variables from the original dataset\n",
    "df_cleaned = df_cleaned.drop(columns=[var for var in variables_to_remove if var in df_cleaned.columns])\n",
    "\n",
    "\n",
    "\n",
    "# Generate new variables based on the specified conditions\n",
    "df_cleaned['HRP_weight'] = df_cleaned['Weight (In Kg)'].apply(lambda x: 1 if x <= 35 else 0)\n",
    "df_cleaned['HRP_height'] = df_cleaned['Height (In Cm)'].apply(lambda x: 1 if x <= 145 else 0)\n",
    "df_cleaned['HRP_BP_Systolic'] = df_cleaned['Blood Pressure (systolic)'].apply(lambda x: 1 if x >= 140 else 0)\n",
    "df_cleaned['HRP_BP_Dystolic'] = df_cleaned['Blood Pressure (Dystolic)'].apply(lambda x: 1 if x >= 90 else 0)\n",
    "df_cleaned['HRP_HBLevel'] = df_cleaned['HB level '].apply(lambda x: 1 if x <= 7 else 0)\n",
    "df_cleaned['HRP_Diabetes_Mellitus'] = df_cleaned['If yes, what?- Identified with_(History of Diabetes Mellitus ()'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_abt'] = df_cleaned['If yes, what?- Identified with_(Previous history of Abortion)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_previous_cSection'] = df_cleaned['If yes, what?- Identified with_(Previous Ceaser)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_Neonatal_Death'] = df_cleaned['If yes, what?- Identified with_(Previous Neonatal Death)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_previous_still_bth'] = df_cleaned['If yes, what?- Identified with_(Previous Still birth)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_malpresentation'] = df_cleaned['If yes, what?- Identified with_(Malpresentation (breech or oth)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_multiple_pregnancy'] = df_cleaned['If yes, what?- Identified with_(Twins or multiple pregnancy)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_short_interval_pregnancy'] = df_cleaned['If yes, what?- Identified with_(Short Inter Pregnancy Interval)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_thyroid'] = df_cleaned['If yes, what?- Identified with_(Thyroid disease)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "df_cleaned['HRP_Tuberculosis'] = df_cleaned['If yes, what?- Identified with_(Tuberculosis)'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "\n",
    "\n",
    "# List of 'HRP_' variable names\n",
    "hrp_variables = [\n",
    "    'HRP_weight', 'HRP_height', 'HRP_BP_Systolic', 'HRP_BP_Dystolic',  'HRP_HBLevel', 'HRP_Diabetes_Mellitus', 'HRP_abt', 'HRP_previous_cSection', \n",
    "    'HRP_Neonatal_Death', 'HRP_previous_still_bth', 'HRP_malpresentation', \n",
    "    'HRP_multiple_pregnancy', 'HRP_short_interval_pregnancy', 'HRP_thyroid', 'HRP_Tuberculosis'\n",
    "]\n",
    "\n",
    "# Create the 'HRP' variable based on the condition\n",
    "# It's set to 1 if any of the 'HRP_' variables is 1\n",
    "df_cleaned['HRP'] = df_cleaned[hrp_variables].any(axis=1).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming the following paths are correct as per the provided script\n",
    "#output_directory = r\"D:\\Current_User-Narendra\\Working_Folder\\Projects\\Ongoing\\DCM\\Output\"\n",
    "output_directory = r\"D:\\Current_User -Julfakar\\New Session 2023-24\\Python Working\\MHU\\Output\"\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "today_output_folder = os.path.join(output_directory, today_date)\n",
    "\n",
    "# Ensure today's output directory exists\n",
    "if not os.path.exists(today_output_folder):\n",
    "    os.makedirs(today_output_folder)\n",
    "\n",
    "# File paths for the cleaned and unique/multiple ID DataFrames\n",
    "cleaned_filename = \"PBI_Follow_up_Processed.xlsx\"\n",
    "unique_ids_filename = \"Unique_FLW_Case.xlsx\"\n",
    "multiple_ids_filename = \"Multiple_IDs_FLW_Case.xlsx\"\n",
    "\n",
    "cleaned_output_path = os.path.join(today_output_folder, cleaned_filename)\n",
    "unique_ids_output_path = os.path.join(today_output_folder, unique_ids_filename)\n",
    "multiple_ids_output_path = os.path.join(today_output_folder, multiple_ids_filename)\n",
    "\n",
    "# Saving the cleaned DataFrame\n",
    "df_cleaned.to_excel(cleaned_output_path, index=False)\n",
    "\n",
    "# Creating and saving unique and multiple ID datasets\n",
    "df_unique_ids_full = df_cleaned.drop_duplicates(subset=['ID'])\n",
    "df_unique_ids_full.to_excel(unique_ids_output_path, index=False)\n",
    "\n",
    "ids_count = df_cleaned['ID'].value_counts()\n",
    "multiple_ids = ids_count[ids_count > 1].index\n",
    "df_multiple_ids = df_cleaned[df_cleaned['ID'].isin(multiple_ids)]\n",
    "df_multiple_ids.to_excel(multiple_ids_output_path, index=False)\n",
    "\n",
    "# Follow-Up Indicator DataFrame operations\n",
    "follow_up_indicator_path = os.path.join(today_output_folder, \"Follow-UP_indicator.xlsx\")\n",
    "df_cleaned = df_cleaned\n",
    "\n",
    "# Finally, save the modified df_cleaned back to the file or a new file as needed\n",
    "#updated_follow_up_indicator_path = os.path.join(today_output_folder, \"Updated_Follow-UP_indicator.xlsx\")\n",
    "#df_cleaned.to_excel(updated_follow_up_indicator_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to: {cleaned_output_path}\")\n",
    "print(f\"Unique ID dataset saved to: {unique_ids_output_path}\")\n",
    "print(f\"Multiple ID dataset saved to: {multiple_ids_output_path}\")\n",
    "#print(f\"Updated Follow-UP indicator dataset saved to: {updated_follow_up_indicator_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
